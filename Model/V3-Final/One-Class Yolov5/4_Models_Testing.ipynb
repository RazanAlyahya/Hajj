{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6687f29c",
      "metadata": {},
      "source": [
        "<h1> Eyes of Hajj </h1>\n",
        "<h3>Hajj Crowd Abnormal Behavior Detection</h3>\n",
        "<h3>Project Workflow</h3>\n",
        "<ol>\n",
        "    <li>Loading the HAJJv2 Dataset.</li>\n",
        "    <li>Extracting the images (frames) from the videos and merge the labesls into a single file for train & test.</li>\n",
        "    <li>Transforming the data to Yolo format where we optain a text file (label) for each image in train & test & val. </li>\n",
        "    <li>Changeing the Yolo feature extractor's backbone to MobileNet/ResNet50 to optimize the feature extraction.</li>\n",
        "    <li>Applaying the Lucas-Kanade algorithm on the frames (images) from the original dataset to estimate the optical flow (Magnitude & Orientation/Direction).</li>\n",
        "    <li>Taking the mean & varience & STD of the optical flow and feed it into the Random Forest classifier to predect the actual class of the abnormal behavior.</li>\n",
        "    <li>Using the Kalman filter with the RF predections to optimaize the Yolo's object tracking.</li>\n",
        "    <li>Evaluating the models' performences on the testing data nad save the output in a new folder.</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffadf094",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing the required libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77521de8",
      "metadata": {},
      "source": [
        "### 8. Evaluating the models' performences on the testing data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d5cde14",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to convert video to frames and store them in a list\n",
        "def video_to_frames(video_path):\n",
        "    # Open the video file\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Check if the video file is opened successfully\n",
        "    if not video_capture.isOpened():\n",
        "        print(\"Error: Could not open video file.\")\n",
        "        return\n",
        "\n",
        "    frames = []\n",
        "\n",
        "    # Loop through the video frames\n",
        "    while True:\n",
        "        ret, frame = video_capture.read()\n",
        "\n",
        "        # Break the loop if we've reached the end of the video\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Resize the frame to 640x640\n",
        "        frame = cv2.resize(frame, (640, 640))\n",
        "\n",
        "        frames.append(frame)\n",
        "\n",
        "    # Release the video capture object\n",
        "    video_capture.release()\n",
        "\n",
        "    return frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afeb46ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_bboxes(bbox_str):\n",
        "    try:\n",
        "        # Evaluate the string while providing safe globals and locals to prevent potential security issues\n",
        "        bbox_list = eval(bbox_str, {\"__builtins__\": None}, {})\n",
        "        parsed_bboxes = []\n",
        "\n",
        "        for bbox_data in bbox_list:\n",
        "            if len(bbox_data) == 5:\n",
        "                bbox = np.array(bbox_data[:4])\n",
        "                confidence = float(bbox_data[4])\n",
        "                parsed_bboxes.append((bbox, confidence))\n",
        "            else:\n",
        "                print(f\"Ignoring invalid bounding box data: {bbox_data}\")\n",
        "\n",
        "        return parsed_bboxes\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing bounding boxes: {e}\")\n",
        "        return []\n",
        "\n",
        "# Function to display and save annotated frames\n",
        "def save_annotated_frames(frames, annotations, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for i, annotation in annotations.iterrows():\n",
        "        frame = frames[i]\n",
        "        frame_number = annotation['Frame_Number']\n",
        "        bboxes_str = annotation['Bboxes']\n",
        "        bboxes = parse_bboxes(bboxes_str)\n",
        "\n",
        "        # Create a copy of the frame to draw bounding boxes\n",
        "        annotated_frame = frame.copy()\n",
        "\n",
        "        for bbox, confidence in bboxes:\n",
        "            x1, y1, x2, y2 = bbox.astype(int)\n",
        "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (100, 0, 255), 2)  # Light red with lower red channel value\n",
        "            cv2.putText(annotated_frame, f'Confidence: {confidence:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 0, 255), 2)\n",
        "\n",
        "        # Save the annotated frame\n",
        "        output_path = os.path.join(output_dir, f'frame_{frame_number}.jpg')\n",
        "        cv2.imwrite(output_path, annotated_frame)\n",
        "\n",
        "# Load the DataFrame from a CSV file (replace 'annotations.csv' with your file path)\n",
        "annotations_df = pd.read_csv('annotations.csv')\n",
        "\n",
        "video_path = \"./HAJJv2_Dataset/Original_Data/Test/Videos/9.mp4\"  # Replace with the path to your video file\n",
        "frames = video_to_frames(video_path)\n",
        "\n",
        "# Specify the output directory for saving frames\n",
        "output_directory = \"./Model_Testing_Results\"\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# Call the save function with your frames, annotations, and output directory\n",
        "save_annotated_frames(frames, annotations_df, output_directory)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
